# HoseoAIChallenge
## 2023 HOSEO AI í”„ë¡œê·¸ë˜ë° ëŒ€íšŒ
### ëŒ€íšŒì†Œê°œ
2023 HOSEO AI í”„ë¡œê·¸ë˜ë° ê²½ì§„ëŒ€íšŒì— ì°¸ì—¬í•˜ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.
ì´ë²ˆ ëŒ€íšŒë¥¼ í†µí•´ ì—¬ëŸ¬ë¶„ì˜ ì°½ì˜ì ì¸ ì†Œí”„íŠ¸ì›¨ì–´ ê°œë°œí™œë™ì„ ë„ëª¨í•˜ë©° ì¸ì¬ë¥¼ ë°œêµ´í•˜ê³  SWì—­ëŸ‰ì„ í–¥ìƒì‹œí‚¤ê³ ì í•©ë‹ˆë‹¤.
ì œê³µë˜ëŠ” ë°ì´í„°ì…‹ì„ ê°€ì§€ê³  ì „ì²˜ë¦¬ë¥¼ ì§„í–‰í•˜ê³ , í•™ìŠµ ëª¨ë¸ì„ ê°œë°œí•˜ì—¬ íƒì§€ìœ¨ì„ í™•ì¸í•˜ê³  íš¨ê³¼ì ì¸ ì „ì²˜ë¦¬ ë° ëª¨ë¸ ê°œë°œì— ëŒ€í•œ ë°œí‘œ í‰ê°€ë¥¼ ê°€ì§€ê²Œ ë©ë‹ˆë‹¤.
ê°œë°œ ì–¸ì–´ëŠ” C, C++, Java, Python ë“± ì–´ë–¤ ì–¸ì–´ë¥¼ ì‚¬ìš©í•˜ì…”ë„ ì¢‹ìœ¼ë©°, í”„ë¡œê·¸ë˜ë° í™˜ê²½ì— ëŒ€í•œ ì œì•½ì‚¬í•­ì€ ì—†ìŠµë‹ˆë‹¤.
ë‹¨, ë¶€ì •í–‰ìœ„(Data Leakage ë“±)ê°€ ì˜ì‹¬ë  ê²½ìš° 0ì  ì²˜ë¦¬ë˜ì˜¤ë©° ì´ ì ì„ ì°¸ê³ í•´ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤.ğŸ˜Š
ìš”êµ¬í•˜ëŠ” ì œì¶œìë£Œì˜ ì–‘ì‹ì— ë§ê²Œ ì‘ì„±í•˜ì—¬ ì œì¶œí•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.
ìš°ìˆ˜í•œ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ëŠ” í•™ìƒì—ê²ŒëŠ” ë°ì´í„°ì¸ì¬ì–‘ì„± í”„ë¡œê·¸ë¨ì— ì°¸ì—¬í•  ìˆ˜ ìˆëŠ” ê°€ì‚°ì ì´ ì£¼ì–´ì§‘ë‹ˆë‹¤.
ì¢‹ì€ ê²°ê³¼ê°€ ìˆìœ¼ì‹œê¸¸ ë°”ë¼ë©°, ë§ì€ ì°¸ì—¬ ë¶€íƒë“œë¦½ë‹ˆë‹¤.
### ëŒ€íšŒì†Œê°œ
 - í˜¸ì„œëŒ€í•™êµ í•™ë¶€ìƒ ì „ì²´
### ëŒ€íšŒì¼ì •
- ë³¸êµ ëŒ€í•™ì›ìƒ ë° í•™.ì„ì‚¬ì—°ê³„ê³¼ì •ìƒ ì°¸ì—¬ ë¶ˆê°€
### ì‹ ì²­ì¼ì •
ì‹ ì²­ì ì ‘ìˆ˜ ë° ë°ì´í„°ì…‹ ì œê³µ 2023. 5. 2.(í™”) ~ 2023. 5. 25 (ëª©)
ê²°ê³¼ ì œì¶œë¬¼ ìˆ˜ì‹œ ì ‘ìˆ˜ 2023. 5. 2.(í™”) ~ 2023. 5. 25 (ëª©)
ë°œí‘œ í‰ê°€ 2023. 5. 26 (ê¸ˆ)
ì‹¬ì‚¬ê²°ê³¼ ë°œí‘œ ë° ìˆ˜ìƒ ëŒ€ìƒì ì„ ì • 2023. 5. 26 (ê¸ˆ)
### í‰ê°€ê¸°ì¤€
 - ë°œí‘œí‰ê°€ 70% + íƒì§€ìœ¨(ì„±ëŠ¥) 30%
### ìƒê¸ˆ
1ë“± (1íŒ€)
30ë§Œì›
2ë“± (2íŒ€)
ê° 20ë§Œì›
3ë“± (3íŒ€)
ê° 10ë§Œì›
## ê³¼ì • ë° ê³¼ì œ
### ë°ì´í„°ì…‹ ë¶„ì„
- ë°ì´í„° ì„¸íŠ¸ì—ëŠ” ì „ë¬¸ê°€ê°€ ìƒì„±í•œ ê³ í’ˆì§ˆ í¬í† ìƒµ ì–¼êµ´ ì´ë¯¸ì§€ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
- ì´ë¯¸ì§€ëŠ” ëˆˆ, ì½”, ì… ë˜ëŠ” ì „ì²´ ì–¼êµ´ë¡œ êµ¬ë¶„ëœ ì„œë¡œ ë‹¤ë¥¸ ì–¼êµ´ì˜ í•©ì„±ì…ë‹ˆë‹¤.
- ì‹¤ì œ ì‚¬ëŒ ì´ë¯¸ì§€ì¸ real: 828ì¥ 
- í•©ì„±ëœ ì‚¬ëŒ ì´ë¯¸ì§€ fake: 710ì¥
- êµ¬ë³„ ë‚œì´ë„ë³„ë¡œ
- easy: 3ì¥ mid: 480ì¥hard: 227ì¥
- ì‚¬ì§„ì€ ì „ë¶€ ì •ë©´, íšŒì „ ì—†ìŒ
- ë°ì´í„°ëŠ” ì „ë¶€ ê°€ë¡œ 600px,ì„¸ë¡œ 600px
### ëª©í‘œ ëª¨ë¸ Case
1. ResNet: VGG16ì— ë¹„í•´ íŒŒë¼ë¯¸í„°ê°€ ì ìœ¼ë¯€ë¡œ ë§ì€ ë ˆì´ì–´ë¥¼ ì‚¬ìš©ê°€ëŠ¥, ë ˆì´ì–´ë³„ ëª¨ë¸ ë¹„êµ
2. VGG16: 
	1. VGG16 Real/Fake :  VGG16ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ real/fake ì´ë¯¸ì§€ë¥¼ êµ¬ë¶„í•˜ëŠ” ì´ì§„ ë¶„ë¥˜ ëª¨ë¸
	2. VGG16 Easy ë°ì´í„° ì¦ê°• í›„ í•™ìŠµ:
	3. VGG16 Easy ë°ì´í„°ê°€ì¤‘ì¹˜ ë¶€ì—¬ í›„ í•™ìŠµ





1. ë°ì´í„°ì…‹ì„ 0.15ë¹„ìœ¨ë¡œ ë‚˜ëˆ  í•™ìŠµ, í…ŒìŠ¤íŠ¸ì…‹ì„ ë‚˜ëˆ„ê¸°
2. í•™ìŠµì…‹ì˜ ì´ë¯¸ì§€ë¥¼ ì¢Œìš° flipì‹œì¼œ ë°ì´í„° ì¦ê°•


## ë°œí‘œìë£Œëª©ì°¨ ##
**ì œëª©: í´ë˜ìŠ¤ í™œì„±í™” ë§µ(CAM) ë° ë°ì´í„°ì…‹ ë¶„ì„ì„ í™œìš©í•œ ì–¼êµ´ ì´ë¯¸ì§€ ë¶„ë¥˜ ê°œì„ **

1. ì†Œê°œ
   - ë¬¸ì œì˜ ë°°ê²½: í•©ì„± ë° ì‹¤ì œ ì–¼êµ´ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•œ ì–¼êµ´ ì´ë¯¸ì§€ ë¶„ë¥˜
   - ì •í™•í•œ ë¶„ë¥˜ì˜ ì¤‘ìš”ì„±ê³¼ ë‹¤ì–‘í•œ ì‘ìš© ë¶„ì•¼ì˜ ì¤‘ìš”ì„± ì†Œê°œ
   
2. ë°ì´í„°ì…‹ ë¶„ì„
   - ë°ì´í„°ì…‹ ì„¤ëª…: ê³ í’ˆì§ˆ í¬í† ìƒµ í•©ì„± ì–¼êµ´ ì´ë¯¸ì§€
   - ì‹¤ì œ ì´ë¯¸ì§€ ë° í•©ì„±ëœ ì´ë¯¸ì§€ ë¶„í¬: ì‹¤ì œ (828ì¥) ëŒ€ í•©ì„± (710ì¥)
   - ì´ë¯¸ì§€ íŠ¹ì§•: ì •ë©´, íšŒì „ ì—†ìŒ, í¬ê¸°: 600px x 600px
   
3. ì´ˆê¸° ì ‘ê·¼ë²•ê³¼ ë„ì „ ê³¼ì œ
   - í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë¶„í•  ì ‘ê·¼ë²•ê³¼ ì œí•œ ì‚¬í•­ ì„¤ëª…
   - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì—ì„œì˜ ê³¼ì í•© ë¬¸ì œ
   
4. ê°œì„ ëœ ì ‘ê·¼ë²•: í•™ìŠµ-í…ŒìŠ¤íŠ¸-ê²€ì¦ ë¶„í• 
   - í•™ìŠµ-í…ŒìŠ¤íŠ¸-ê²€ì¦ ë¶„í•  ì†Œê°œ
   - ê²€ì¦ ì„¸íŠ¸ì˜ ì¥ì 
   - í‰ê°€ ì§€í‘œ: ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜
   
5. í´ë˜ìŠ¤ í™œì„±í™” ë§µ(CAM)ì„ í†µí•œ ëª¨ë¸ ê²°ì • ì´í•´
   - í´ë˜ìŠ¤ í™œì„±í™” ë§µ(CAM) ì†Œê°œ
   - ëª¨ë¸ì˜ ì˜ì‚¬ ê²°ì •ê³¼ì • ì‹œê°í™”
   - ë¶„ë¥˜ì— ì¤‘ìš”í•œ ì˜ì—­ í•´ì„
   
6. ê²°ê³¼ ë° ë¶„ì„
   - ì´ˆê¸° ì ‘ê·¼ë²•ê³¼ ê°œì„ ëœ ì ‘ê·¼ë²• ë¹„êµ
   - í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì„±ëŠ¥ ì§€í‘œ: ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜
   - CAM ë¶„ì„: ëª¨ë¸ì˜ ì´ˆì  ì˜ì—­ì— ëŒ€í•œ í†µì°°ë ¥
   
7. ê²°ë¡ ê³¼ í–¥í›„ ì—°êµ¬
   - ê²°ê³¼ ìš”ì•½
   - ì œí•œ ì‚¬í•­ ë° í–¥í›„ ê°œì„  ê°€ëŠ¥ì„±
   - ì‘ìš© ë¶„ì•¼ ë° ì¶”ê°€ ì—°êµ¬ ë°©í–¥
   
8. ì§ˆì˜ì‘ë‹µ ë° í† ë¡ 
   - ê´€ê°ìœ¼ë¡œë¶€í„°ì˜ ì§ˆë¬¸ ë° í† ë¡  ì´ˆëŒ€
   
9. ì°¸ê³ ë¬¸í—Œ
   - ê´€ë ¨ ë…¼ë¬¸, ê¸°ì‚¬ ë° ìë£Œ ì¸ìš©
  
   




```
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader

# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
batch_size = 64
num_epochs = 100
learning_rate = 0.001

# ë°ì´í„° ê²½ë¡œ ì„¤ì •
train_data_path = r"/content/drive/MyDrive/dataset/train"
test_data_path = r"/content/drive/MyDrive/dataset/test"

# ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥ ê²½ë¡œ
weight_save_path = r"/content/drive/MyDrive/dataset/"

# ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€í™˜
transform = transforms.Compose([
    transforms.Resize((600, 600)),  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    transforms.RandomHorizontalFlip(),  # ê°€ë¡œ ë’¤ì§‘ê¸°
    transforms.RandomRotation(10),  # ëœë¤í•œ ê°ë„ë¡œ íšŒì „
    transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # ì´ë¯¸ì§€ ì •ê·œí™”
])

# í•™ìŠµ ë°ì´í„°ì…‹ê³¼ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ
train_dataset = ImageFolder(root=train_data_path, transform=transform)
test_dataset = ImageFolder(root=test_data_path, transform=transform)

# ë°ì´í„° ë¡œë” ìƒì„±
train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)

# GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.fc1 = nn.Linear(32 * 150 * 150, 64)  # ì…ë ¥ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        self.relu3 = nn.ReLU()
        self.dropout = nn.Dropout(0.5)  # ë“œë¡­ì•„ì›ƒ ì¶”ê°€
        self.fc2 = nn.Linear(64, 2)  # í´ë˜ìŠ¤ ê°œìˆ˜ì— ë§ê²Œ ì¶œë ¥ í¬ê¸° ì¡°ì •

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu1(x)
        x = self.pool1(x)
        x = self.conv2(x)
        x = self.relu2(x)
        x = self.pool2(x)
        x = x.view(x.size(0), -1)
        x = self.fc1(x)
        x = self.relu3(x)
        x = self.dropout(x)  # ë“œë¡­ì•„ì›ƒ ì ìš©
        x = self.fc2(x)
        return x

# ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
model = Model()  # ëª¨ë¸ì„ ì •ì˜í•´ì•¼ í•¨
model = model.to(device)

# ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì € ì •ì˜
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=learning_rate)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)  # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§

# í•™ìŠµ ë° í‰ê°€
for epoch in range(num_epochs):
    model.train()
    train_loss = 0.0
    train_correct = 0
    
    for images, labels in train_loader:
        images = images.to(device)
        labels = labels.to(device)
        
        optimizer.zero_grad()
        outputs = model(images)
        
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        _, predicted = torch.max(outputs.data, 1)
        train_correct += (predicted == labels).sum().item()
        train_loss += loss.item() * images.size(0)
    
    train_accuracy = 100.0 * train_correct / len(train_dataset)
    train_loss /= len(train_dataset)
    
    model.eval()
    test_loss = 0.0
    test_correct = 0
    
    with torch.no_grad():
        for images, labels in test_loader:
            images = images.to(device)
            labels = labels.to(device)
            
            outputs = model(images)
            
            loss = criterion(outputs, labels)
            
            _, predicted = torch.max(outputs.data, 1)
            test_correct += (predicted == labels).sum().item()
            test_loss += loss.item() * images.size(0)
    
    test_accuracy = 100.0 * test_correct / len(test_dataset)
    test_loss /= len(test_dataset)
    
    print(f"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%")
    
    # ê° epochë§ˆë‹¤ ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ì¥
    torch.save(model.state_dict(), f"{weight_save_path}/model_epoch_{epoch+1}.pth")
    
    # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§ ì ìš©
    scheduler.step()

```
Case1


transform = transforms.Compose([
    transforms.Resize((600, 600)),  # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    transforms.RandomHorizontalFlip(),  # ê°€ë¡œ ë’¤ì§‘ê¸°
    transforms.RandomRotation(10),  # ëœë¤í•œ ê°ë„ë¡œ íšŒì „
    transforms.ToTensor(),  # ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # ì´ë¯¸ì§€ ì •ê·œí™”
])

